### 目录

* <a href="#layoutSubviews什么时候调用">layoutSubviews什么时候调用</a>
* <a href="#Xcode中的workspace">Xcode中的workspace、xcodeproj、target、schema的关系 </a>
* <a href="#malloc和free">malloc和free</a>
* <a href="#静态库.a和.framework">静态库.a和.framework</a>
* <a href="#异步渲染原理 && setNeedsDisplay">异步渲染原理 && setNeedsDisplay</a>
* <a href="#直播相关协议">直播相关协议</a>
* <a href="#渲染图片怎么优化">渲染图片怎么优化</a>
* <a href="#数组越界为什么会崩溃">数组越界为什么会崩溃</a>
* <a href="#解决网络请求依赖关系">解决网络请求依赖关系</a>
* <a href="#OOM">OOM</a>
* <a href="#H.264和H.265">H.264和H.265</a>
* <a href="#dSYM是什么">dSYM是什么</a>


### 详情



<a id="layoutSubviews什么时候调用"></a>

<font color=#FF4500>
### layoutSubviews什么时候调用
</font>

```
init初始化不回触发
addSubView会触发
改变view的大小会触发,改变origin不回触发
改变子view的大小会触发,改变子view的origin不回触发
改变bounds会触发
旋转实测没触发(网上说触发),只是控制器self.view触发
setNeedsDisplay(使当前的layout无效,标记待刷新)会触发
```
*  如果调用layoutIfNeeded并且已被标记为待刷新,不回等到runloop结束,会立即刷新

<a id="Xcode中的workspace"></a>
<font color=#FF4500>
### Xcode中的workspace、xcodeproj、target、schema的关系 
</font>

[https://zhuanlan.zhihu.com/p/52130048](https://zhuanlan.zhihu.com/p/52130048)

* Target: 工程中最小可表一单元,每一个target对应一个编译输出,这个输出可以是一个链接库,一个可执行文件或者一个资源包.它定义了这个输出怎么被build的所有细节. 平时Build Settings，Build Phases 中配置的各种选项，大部分都是对应到指定的 target 的
	 * 编译选项,比如使用的编译器,目标平台,flag,头文件搜索路径等等
	 * 哪些源码或者资源文件会被编译打包,哪些静态库,动态库会被链接
	 * build时前置依赖,执行脚本文件
	 * build生成目标的签名, Capabilities等属性
* 每次我们在 Xcode 中 run/test/profile/analyze/archive 时，都必须指定一个 target
* 工程中的 targets 有时候会共享很多代码、资源，这些相似的 targets 可能对应同一个应用的不同版本，比如 iPad 版和 iPhone 版，或者针对不同市场的版本
* Project: 就是一个xcode工程,它管理这个工程下的targets集合以及他们的源码,引用的资源,framework等
* Project是管理资源的容器,单独无法被编译.只有有一个target.也可以对project进行配置,包括基本信息和编译选项,会应用到所有targets中, 如果单个target有自己的配置,会覆盖project配置
* Workspace: 当一个target被多个不同的项目依赖,或者project之间相互引用,这时需要把projects放到相同层级上来,管理他们的容器就是Workspac. 不参与任何编译链接过程
	 * xcode中projects,记录他们在finder中的引用位置
	 * 一些用户界面的自定义信息(窗口位置,顺兴,偏好等)
* Scheme: 针对一个指定的target,scheme定义了build这个target时使用的配置选项,执行的任务,环境参数等.可以理解为一个工作流或者蓝图.scheme中预设六个主要的工作流: Build,Run,Test,Profile,Ananlyze,Archive.
* Scheme 中最重要的一个配置是选择 target 的 build configuration，对每一个 project，会有两个默认的 build configuration：debug 和 release,可以自己新增
* 每个 configuration 对应了 build target 时不同的参数集，比如宏，编译器选项，bundle name 等等
* Scheme 还可以设置
	 * 环境变量（Environment Variables）
	 * runtime，内存管理，日志，帧率检测等调试选项(加载时间)
	 * App 执行时的系统语言、模拟的定位坐标、国家等环境参数
	 * 启动时设置给 UserDefaults 的参数

<a id="malloc和free"></a>
<font color=#FF4500>
### malloc和free
</font>

* 详细:[https://www.huaweicloud.com/articles/baea6198b9bbe8da4875c09f081edd21.html](https://www.huaweicloud.com/articles/baea6198b9bbe8da4875c09f081edd21.html)
* 申请内存后必须坚持是否分配成功(堆)
* 不允许在未分配的内存上调用free，标准明确指出,连续释放两次crash
* 释放后最后置NULL指针
* 申请后最好强转类型,可以躲过一些编译检查
*  free释放的事指向的内存,指针没有释放,只不过指针指向的内容是未定义的,垃圾内存.为什么? 如果被free的内存已被分配,且处于被分配的中间

	```
	 +- New pointer    +- Old pointer
	 v                 v
	+------------------------------------+
	|                  <Dodgy bit>       |
	+------------------------------------+
	```
* 可以定义类似myFree函数解决多次释放 {free(p),p = NUL}
*  大多数实现分配的存储空间比要求的要稍微大一些,额外的空间就管理信息(分配块的长度,下一个分配块的指针等待).一般用结构体存储

	```
	 struct mem_control_block { 
	 	int is_available; //一般来说应该是一个可用空间的首地址，但这里英文单词却显示出空间是否可用的一个标记
     	int size; //这是实际空间的大小  
     	};
	```
* 为什么free的时候不传size? 有一个地址簿记录着已分配的

<a id="静态库.a和.framework"></a>
<font color=#FF4500>
### 静态库.a和.framework
</font>

* 库: 共享代码的方式.一般分为静态库和动态库.
* 静态库: 编译的时候会直接拷贝一份到目标程序里,这段代码在目标程序里就不会改变了.好处没有外部依赖,直接可以运行,缺点增大目标程序体积.有多份冗余拷贝
* 动态库: 链接时不复制.运行时由系统加载到内存,工程序使用.系统只加载一次,多个程序共用.有点不影响目标程序体积.缺点: 性能上的损失,依赖外部环境. 自己开发的静态库还是动态库都要复制到目标程序,所以苹果又把这个交友embeded framework.
* 静态库形式: a.  和 .framework
* 动态库形式: 系统.framework   .dylib .tbd
* 系统的.framework是动态库,我们自己建立的是静态库
* .a是一个纯二进制文件. .framework还有资源文件
* .a不能直接使用,需要.h配合.  .framework可以直接使用
* .a + .h + .sourceFile = .framework
* 为什么使用静态库: 共享代码,程序模块化.三方sdk
* 注意: category 需设置other linker flags. 还可能没加载. 需要手动设置方法调用


<a id="异步渲染原理 && setNeedsDisplay"></a>
<font color=#FF4500>
### 异步渲染原理 && setNeedsDisplay
</font>

*  调用[UIView setNeedsDisplay]不回立马发送对应视图的绘制工作,调用后回调用同名方法 [view.layer setNeedsDisplay],并在view上标记为待刷新. 当runloop将要结束的时候才会调用[CALyer display]进入仕途真正绘制工作
*  setNeedsDisplay, setNeedsLayout都是异步执行
	 * setNeedsDisplay会自动调用drawRect,这样可以拿到UIGraphicsGetCurrentContext
	 * setNeedsLayout(会是当前layout无效)会默认调用layoutSubViews,当想调整子视图布局的时候调用setNeedsLayout
	 * layoutSubViews方便数据计算, drawRect方便视图绘制
*  异步绘制绘制
	* 自定义CALyer给view.
	* [CALyer display]的时候在子线程去绘制生成位图,绘制包括计算ctframer,ctline,ctrun,drawLine等
	* 将绘制好的位图,切到主线程复制给view.content
*  setNeedsLayout可能会多次被调用,所以异步绘制需要一个atomicInt自增来防止上一次无效的绘制. setNeedsLayout调用一次自增一次.在上一次异步绘制的开始,生成image,切主线程赋值layer.content的时候都要比对这个自增数,如果自增数变化,证明中间调用setNeedsLayout了,取消当前(上一次)处理流程

<a id="直播相关协议"></a>
<font color=#FF4500>
### 直播相关协议
</font>

* 扫盲: [https://doc.douyu.tv/ddse/preview/space/13634?sid=204](https://doc.douyu.tv/ddse/preview/space/13634?sid=204)
* webrtc(Web Real-Time Communication): 是一个支持网页浏览器进行实时语音对话或视频对话技术,不借助中间媒介的情况下,建立点对点连接(Peer-to-Peer),pc上chrome支持比较好,底部c++实现,提供浏览器相关的API以外，还能在IOS、Android、Mac、Linux、Windows全平台上运行.
 * webrtc通过信令服务器交换彼此的媒体描述信息(sdp),包括数据格式(h264,vp8),以及网络地址(host地址,公网地址,turn服务器地址).交换后选择合适的音视频格式已经网络地址通信
 * webrtc客户端之间建立网络连接的过程叫做ice
  * 位于同一局域网,或者都位于公网,采用直连
  * 位于不同局域网,双方本地网络地址不可直接访问,位于不同NAT后面,需要NAT穿透(打洞),(NAT局域网地址到公网地址技术)
  * 通过服务器中转
 * webrtc涉及到的协议比较多,其中信令负分没有具体规定,通常使用tcp,包括http,websock等,媒体协商使用sdp协议,音视频传输通常使用udp,主要协议如下
  * SDP,描述媒体信息,通过信令进行交换
  * STUN, ice交互使用
  * DTLS,音视频加密传输使用
  * RTP和RTCP(基于udp),音视频内容传输和反馈(拉流)
* hls: (HTTP Live Streaming)协议播放直播流
 * 基于http文件下载,引入.m3u8文件,里面对应若干ts文件,ts文件里面粗放真正视频数据.m3u8文件只是存放了一些ts文件的配置信息和路径.当视频播放时,m3u8是动态改变的,h5中video标签会解析这个文件,找到对应ts文件播放, 一般为了加快速度,.m3u8放在web服务器,ts文件放在cdn
 * 流程: http请求m3u8的url,服务端返回一个m3u8的播放列表,列表实时更新,一般一次给出6段数据的url.客户端解析m3u8的播放列表,再按序请求每一段的url,获取ts数据流.
 * 假设列表包含5个ts文件,每个ts文件5s那么延迟就是25s,主播需要将视频录制好上传上去,还有延迟.如果缩短ts时长,将会加大服务器压力
* 音视频采集:
 * 摄像头--> AVCaptureSession-->原始视频数据--->x264编码--->h.264数据
 * 麦克风--> AVCaptureSession-->原始音频流-->faac编码--->aac数据
 * 对编码后的音,视频进行组装封包flv,mp4
 * 建立rtmp推送到Nginx服务器
* ffmpeg是一套编码库
* rtmp:  Real Time Messaging Protocol,视频直播协议,基于flash无法在ios浏览器播放,实时性比hls更好,一般使用推流,基于长连接tcp
* 目前公司存在两种直播方式,一种是传统的主播基于rtmp(基于ffmpeg实现)推流到cdn的直播形式,另一种是基于webrtc的主播间互动并推流到cdn,比如两人连麦,多人连麦.  当主播从房间直播切到连麦业务,目前推2路流,一路房间直播流,一路连麦数据流.存在流量浪费,如果网络不好,rtmp的效果较差,而webrtc的优秀抗弱网能力则可以解决
* 线上用户观看直播都是使用rtmp从cdn拉流，大约有10多秒的延时，如果主播采用webrtc推流，则用户侧也可采用webrtc拉流，可将延时缩减到1秒以内，提高用户主播互动的实时性


<a id="渲染图片怎么优化"></a>
<font color=#FF4500>
### 渲染图片怎么优化
</font>

* `imageNamed:`可以缓存已经加载的图片,使用时,先在系统缓存中寻找图片,如果没有从Bundle找.当渲染到屏幕时才解码图片,并将解码的图片保留到缓存,收到内存警告释放缓存.`imageWithContentsOfFile`不缓存,只加载.
* png压缩是对像素做索引存储,jpg是保存亮度,减少像素.解码后的图片会大很多
* SDWebImage下载图片后或者从硬盘取的缓存图片会在子线程解码图片并保存图片,避免重复解码, 并在主线程回调赋值给imageview.使用函数`CGBitmapContextCreate`
* SDWebImage如果options设置`SDWebImageDownloaderScaleDownLargeImages`重采样,会触发重采样,一般用向下采样.将图片裁剪成imageview大小.减少内存.
* 如果图片很大解密可能crash.
	* 服务端不要下发很大的图
	* 使用CATiledLayer将大图分解成小图显示
	* 将大图缩放指定大小


<a id="数组越界为什么会崩溃"></a>
<font color=#FF4500>
### 数组越界为什么会崩溃
</font>

内存越界崩溃根源一般是下面两种情况: 

* 权限问题-访问了没有相应权限的地址,一般读越界引起的崩溃都是这种.多数写越界也会直接或间接引起这种问题
* 代码执行出错- 执行了非法的代码或者由于数据错误引起的代码执行异常


<a id="解决网络请求依赖关系"></a>
<font color=#FF4500>
### 解决网络请求依赖关系
</font>

```objective-c
1. NSOperation的addDependecy,缺点不好保证请求1回调的时候去请求2
2. 请求1的回调中,执行请求2. 
3. dispatch_group
	dispatch_group_async(group_t, concurentQueue, ^{// 请求1});
    dispatch_group_notify(group_t, dispatch_get_main_queue(), ^{// 请求2});
4. dispatch_barrier_async
	dispatch_async(concurent_t, ^{// 请求1});
    dispatch_barrier_async(concurent_t, ^{// 请求2});
5. 信号量
	dispatch_semaphore_t sem_t = dispatch_semaphore_create(0);
    dispatch_async(concurent_t, ^{dispatch_semaphore_signal(sem_t);});
    dispatch_async(concurent_t, ^{dispatch_semaphore_wait(sem_t, DISPATCH_TIME_FOREVER);
        // 请求2开始});
```


<a id="OOM"></a>
<font color=#FF4500>
### OOM
</font>

* Out Of Memory,指的是当前用户使用内存过高,被系统强制终止,是由于 iOS 的 Jetsam 机制造成的一种“另类” Crash，它不同于常规的 Crash，通过 Signal 捕获等 Crash 监控方案无法捕获到 OOM 事件
* 分为FOOM和BOOM
* 往往OOM比普通crash要多
* Jetsam强杀是通过SIGKILL,SIGKILL的原因有:
	* App 更新了版本
	* App 发生了崩溃
	* 用户手动退出
	* 操作系统更新了版本
	* App 切换到后台之后进程终止
	* **WatchDog 崩溃**:如果我们的应用程序对一些特定的UI事件（比如启动、挂起、恢复、结束）响应不及时，Watchdog 会把我们的应用程序干掉，并生成一份响应的 crash 报告
	* 后台启动
	* XCTest/UITest 等自动化测试框架驱动
	* 应用 exit 主动退出

* 定位OOM:
	* 方案1: 用上面的排除法,启动时候,判断上一次SIGKILL的类型
	* 方案2: 
		* 在子线程监控应用内存,达到阈值的时候
		* 用OOMDetector(腾讯)执行一次泄露检查拿到分配内存的堆栈. 这个检查会挂起除当前所有线程,建议在主线程调用.耗时1s以上.(thread_suspend)
		* 本次/或者下次启动上传到服务器

* 相关文章
	 * [https://cloud.tencent.com/developer/article/1724947](https://cloud.tencent.com/developer/article/1724947)
	 * [https://juejin.cn/post/6844903749836603400#heading-5](https://juejin.cn/post/6844903749836603400#heading-5)
	 * [https://github.com/Tencent/OOMDetector](https://github.com/Tencent/OOMDetector)
	 * [https://wetest.qq.com/lab/view/367.html](https://wetest.qq.com/lab/view/367.html)
	

<a id="H.264和H.265"></a>
<font color=#FF4500>
### H.264和H.265
</font>

* h.264是一种视频压缩标准,也是一种被广泛使用的高精度视频的录制,压缩和发布格式.因其是蓝光广播的一种编码标准而注明,所有蓝光播放器都必须能解码h.264,更重要的是苹果当初抛弃adobe的vp6编码选择h264. 相比较执勤啊的编码标准有一些新特性, 如多参看帧的运动补偿, 变快尺寸运动补偿,帧内预测编码等,而使得其有更高的视频质量和更低的码率
* h.265/HEVC的编码架构大致上和h264/AVC相似,也主要包括帧内预测,帧间预测,转换,量化,去区块滤波器,熵编码等模块.编码单位来看,h264每个宏块都是固定16x16像素,h265则从8x8到64x64编码效率提高了. 帧内预测模式h264支持8个方向, h265支持33种,并提供了更好的运动补偿和食量预测
* 相同图像质量下h265编码的视频麻溜比h264减少39~44%
* 升级iOS11后,手机内存的照片不再用JPEG了, 而是HEIF,文件后缀为.heic(很小).其编码就是HEVC格式又称h.265,同事视频也用HEVC作为编码器,对应文件后缀还是.mov
* h264理论依据: 相邻几幅图片中, 一般有差别的像素有10%,亮度变化<2%,色差变化<1%.
	* I帧,关键帧,完整保留,解码时无需参考其他帧,JPEG压缩及传输
	* P帧,前向预测编码帧,表示这一帧跟之前的一个关键帧或P帧的差别,解码时候需要前帧加上本帧定义的差别生成最终画面,没有画面信息,幼教差别帧,预测帧
	* B帧,双向预测内插编码帧,要结合前一个画面和后一个画面,以及本帧数据叠加处最终画面.由前面的I/P和后面的P来预测,压缩率最高
	* 当于东变化小,一个序列可以一个I帧,后面一直P,B
	* 变化大时候,一个序列比较短,一个I,和3,4个P
* 软编码: CPU编码
* 硬编码: 显卡GPU
* 比较: 
	* 软编码: 实现直接,简单,参数调整方便,升级简单,cpu负载中,性能低,低码率通常比硬编码好一点
	* 硬编码: 性能高,部分产品再GPU硬件平台上一直了优秀的软编码算法(x264)
	* ios8之前没开发硬编码`Video ToolBox`
	* h264,h264一样的api参数不同
* 参考文章: 
	* [https://juejin.cn/post/6844903566218362893#heading-20](https://juejin.cn/post/6844903566218362893#heading-20)
	* [https://www.daimajiaoliu.com/daima/385497059900408](https://www.daimajiaoliu.com/daima/385497059900408)
	* [https://juejin.cn/post/6844903566201585672#heading-9](https://juejin.cn/post/6844903566201585672#heading-9)

	
	
<a id="dSYM是什么"></a>
<font color=#FF4500>
### dSYM是什么
</font>

* dsym: 保存按DWARF格式保存调试信息的文件
* DWARF: 是一种被众多编译器和调试器使用的用于支持源代码级别调试的调试文件格式
* dsym怎么生成的:
	 * 读取debug map
	 * 从.o文件中加载`__DWARF`
	 * 重新定位地址
	 * 将全部DWARF打包成dsym bundle
* dsym中记录的是偏移钱的函数地址
* 崩溃分析
	* 从crash日志里面获取偏移地址,找`Binary Images`的第一个地址
	* 找到`偏移前的地址 = 偏移后的地址(错误信息地址) - 偏移量`
	* `dwarfdump --lookup 偏移前的地址 TestInject.app.dSYM`定位错误代码
* [https://www.jianshu.com/p/faf0e26eb882](https://www.jianshu.com/p/faf0e26eb882)

